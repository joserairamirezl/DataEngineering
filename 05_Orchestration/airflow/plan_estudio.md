# ğŸ§­ Plan de Estudio â€” Data Engineering

## MÃ³dulo: 05_Orchestration

### Tema: Apache Airflow

---

## ğŸ¯ Objetivo del mes

Dominar los fundamentos de **Apache Airflow** como orquestador de *workflows* de datos, entendiendo su arquitectura, componentes principales y las buenas prÃ¡cticas para desplegar, programar y monitorear DAGs de forma profesional.
Al finalizar el mes deberÃ­as ser capaz de:

* Crear, ejecutar y depurar DAGs en Airflow.
* Entender la arquitectura y los componentes principales (Scheduler, Executor, Webserver, Metadata DB).
* Integrar Airflow con herramientas comunes del ecosistema de datos (dbt, Spark, AWS, GCP).
* Automatizar pipelines reproducibles y observables.

---

## ğŸ“… Semana 1 â€” Fundamentos y Arquitectura de Airflow

**Objetivo:** Comprender quÃ© resuelve Airflow, su arquitectura interna y su flujo de ejecuciÃ³n.

**Temas clave (80/20):**

* Â¿QuÃ© es Apache Airflow y por quÃ© se usa en Data Engineering?
* Conceptos fundamentales: DAGs, Tasks, Operators, Schedulers, Executors.
* Arquitectura general: Webserver, Scheduler, Metadata DB, Worker.
* InstalaciÃ³n local y estructura de un proyecto Airflow.
* CreaciÃ³n de tu primer DAG y ejecuciÃ³n manual.

**Actividades prÃ¡cticas:**

* Instalar Airflow en entorno local o Docker Compose.
* Crear un DAG simple (por ejemplo, ETL con tareas dummy).
* Navegar por la UI y observar el flujo de tareas.

---

## ğŸ“… Semana 2 â€” Operators, Hooks y XComs

**Objetivo:** Aprender a conectar Airflow con otros sistemas y crear DAGs dinÃ¡micos y reutilizables.

**Temas clave (80/20):**

* Tipos de Operators: *BashOperator*, *PythonOperator*, *EmailOperator*, *BranchOperator*.
* Uso de Hooks y conexiones (AWS, GCP, Databases).
* Variables y parÃ¡metros en tareas.
* ComunicaciÃ³n entre tareas con *XComs*.
* Plantillas Jinja y macros.

**Actividades prÃ¡cticas:**

* Crear un DAG con PythonOperator que procese datos.
* Implementar conexiÃ³n a una base de datos o API con Hook.
* Pasar datos entre tareas usando XComs.
* Configurar variables y templates dinÃ¡micos.

---

## ğŸ“… Semana 3 â€” ProgramaciÃ³n, Monitoreo y Logging

**Objetivo:** Dominar la ejecuciÃ³n automatizada, monitoreo y manejo de logs y errores.

**Temas clave (80/20):**

* ConfiguraciÃ³n de *schedules* (CRON, presets, triggers).
* Retries, SLA, dependencias y *task context*.
* Logging: estructura de logs, almacenamiento y depuraciÃ³n.
* Monitoreo desde la UI y mÃ©tricas bÃ¡sicas.
* IntegraciÃ³n con Prometheus/Grafana para observabilidad avanzada.

**Actividades prÃ¡cticas:**

* Configurar un DAG con retries y alertas de fallo.
* Analizar logs y estados de ejecuciÃ³n.
* Probar una integraciÃ³n simple con Prometheus o un email de alerta.

---

## ğŸ“… Semana 4 â€” Integraciones Avanzadas y Despliegue

**Objetivo:** Llevar Airflow a un entorno productivo, integrÃ¡ndolo con pipelines reales y aplicando buenas prÃ¡cticas.

**Temas clave (80/20):**

* IntegraciÃ³n con dbt, Spark o BigQuery.
* Despliegue con Docker Compose, Helm o MWAA (Managed Workflows on AWS).
* Versionado de DAGs con Git.
* ModularizaciÃ³n y testing de DAGs.
* Buenas prÃ¡cticas de arquitectura y seguridad (RBAC, Connections, Secrets).

**Actividades prÃ¡cticas:**

* Desplegar Airflow con Docker Compose.
* Versionar DAGs con Git y configurar CI/CD (GitHub Actions).
* Integrar Airflow con un pipeline dbt o Spark simple.

---

## ğŸ§  Resultado al final del mes

DeberÃ­as poder:
âœ… Comprender y explicar la arquitectura de Airflow.
âœ… Crear y ejecutar DAGs funcionales con dependencias, retries y XComs.
âœ… Monitorear y depurar pipelines de datos.
âœ… Integrar Airflow con sistemas externos y aplicar buenas prÃ¡cticas de despliegue.

---

## ğŸ“š Recursos recomendados

**DocumentaciÃ³n oficial:**

* [Apache Airflow Docs](https://airflow.apache.org/docs/)
* [Airflow Concepts Overview](https://airflow.apache.org/docs/apache-airflow/stable/concepts.html)

**Videos / Playlists:**

* *â€œAirflow Tutorial for Beginnersâ€ â€“ TechWorld with Nana*
* *â€œAirflow in Production â€“ Astronomer Academy (Free)*

**Repositorios Ãºtiles:**

* [`apache/airflow`](https://github.com/apache/airflow) â€“ proyecto oficial
* [`puckel/docker-airflow`](https://github.com/puckel/docker-airflow) â€“ despliegue Docker clÃ¡sico
* [`astronomer/airflow-demo`](https://github.com/astronomer/airflow-demo) â€“ ejemplos modernos
